import numpy as np import pandas as pd

from sklearn.model_selection import train_test_split 
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.preprocessing import LabelEncoder 
from sklearn.pipeline import Pipeline 
from sklearn.naive_bayes import MultinomialNB 
from sklearn.ensemble import RandomForestClassifier 
from sklearn.metrics import accuracy_score, classification_report

import spacy

columns = ['id','country','Label','Text']
df = pd.read_csv("twitter_training.csv",names = columns)
print(df.shape)
df.head()

df.dropna(inplace=True)

nlp = spacy.load("en_core_web_sm")

def preprocess(text):
    # remove stop words and lemmatize the text
    doc = nlp(text)
    filtered_tokens = []
    for token in doc:
        if token.is_stop or token.is_punct:
            continue
        filtered_tokens.append(token.lemma_)
    
    return " ".join(filtered_tokens) 

df['Preprocessed Text'] = df['Text'].apply(preprocess)

le_model = LabelEncoder()
df['Label'] = le_model.fit_transform(df['Label'])

X_train, X_test, y_train, y_test = train_test_split(df['Preprocessed Text'], df['Label'], test_size=0.2, random_state=42, stratify=df['Label'])

print("Shape of X_train: ", X_train.shape)
print("Shape of X_test: ", X_test.shape)

clf = Pipeline([('vectorizer_tri_grams', TfidfVectorizer()),('naive_bayes', (MultinomialNB()))])

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
print(accuracy_score(y_test, y_pred))

print(classification_report(y_test, y_pred))

clf = Pipeline([('vectorizer_tri_grams', TfidfVectorizer()),('naive_bayes', (RandomForestClassifier()))])

y_pred = clf.predict(X_test)

print(accuracy_score(y_test, y_pred))

print(classification_report(y_test, y_pred))

test_df = pd.read_csv('twitter_validation.csv', names=columns)
test_df.head()

test_text = test_df['Text'][10]
print(f"{test_text} ===> {test_df['Label'][10]}")

test_text_processed = [preprocess(test_text)]
test_text_processed

test_text = clf.predict(test_text_processed)

classes = ['Irrelevant', 'Natural', 'Negative', 'Positive']

print(f"True Label: {test_df['Label'][10]}")
print(f'Predict Label: {classes[test_text[0]]}')

import matplotlib.pyplot as plt
import seaborn as sns

# Plot Label Distribution
plt.figure(figsize=(8, 6))
sns.countplot(x=df['Label'], palette="viridis")
plt.title("Sentiment Label Distribution")
plt.xlabel("Sentiment Classes")
plt.ylabel("Count")
plt.xticks(ticks=[0, 1, 2, 3], labels=classes)
plt.show()

plt.figure(figsize=(7, 7))
df['Label'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'salmon', 'purple'])
plt.title('Sentiment Class Distribution')
plt.ylabel('')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))

# Select only numeric columns
numeric_df = df.select_dtypes(include=['number'])

# Compute correlation
correlation_matrix = numeric_df.corr()

# Plot heatmap
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Feature Correlation Heatmap')
plt.show()

df['Text Length'] = df['Text'].apply(lambda x: len(x.split()))

plt.figure(figsize=(8, 6))
sns.histplot(df['Text Length'], bins=20, kde=True, color='blue')
plt.title("Distribution of Text Length in Tweets")
plt.xlabel("Number of Words")
plt.ylabel("Frequency")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()
